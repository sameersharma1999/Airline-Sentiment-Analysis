{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# <-- Import Libraries -->\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "from kerastuner import HyperModel\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import json\n",
    "import pickle \n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('airline_sentiment_analysis.csv')  # Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11536</th>\n",
       "      <td>14633</td>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir my flight was Cancelled Flightled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11537</th>\n",
       "      <td>14634</td>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir right on cue with the delaysðŸ‘Œ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11538</th>\n",
       "      <td>14635</td>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11539</th>\n",
       "      <td>14636</td>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11540</th>\n",
       "      <td>14638</td>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11541 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 airline_sentiment  \\\n",
       "0               1          positive   \n",
       "1               3          negative   \n",
       "2               4          negative   \n",
       "3               5          negative   \n",
       "4               6          positive   \n",
       "...           ...               ...   \n",
       "11536       14633          negative   \n",
       "11537       14634          negative   \n",
       "11538       14635          positive   \n",
       "11539       14636          negative   \n",
       "11540       14638          negative   \n",
       "\n",
       "                                                    text  \n",
       "0      @VirginAmerica plus you've added commercials t...  \n",
       "1      @VirginAmerica it's really aggressive to blast...  \n",
       "2      @VirginAmerica and it's a really big bad thing...  \n",
       "3      @VirginAmerica seriously would pay $30 a fligh...  \n",
       "4      @VirginAmerica yes, nearly every time I fly VX...  \n",
       "...                                                  ...  \n",
       "11536  @AmericanAir my flight was Cancelled Flightled...  \n",
       "11537         @AmericanAir right on cue with the delaysðŸ‘Œ  \n",
       "11538  @AmericanAir thank you we got on a different f...  \n",
       "11539  @AmericanAir leaving over 20 minutes Late Flig...  \n",
       "11540  @AmericanAir you have my money, you change my ...  \n",
       "\n",
       "[11541 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels='Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11541 entries, 0 to 11540\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   airline_sentiment  11541 non-null  object\n",
      " 1   text               11541 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 180.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if data set is imbalanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.795252\n",
       "positive    0.204748\n",
       "Name: airline_sentiment, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Imbalanced Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>positive</td>\n",
       "      <td>@virginamerica Well, I didn'tâ€¦but NOW I DO! :-D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0          positive  @VirginAmerica plus you've added commercials t...\n",
       "4          positive  @VirginAmerica yes, nearly every time I fly VX...\n",
       "5          positive    @virginamerica Well, I didn'tâ€¦but NOW I DO! :-D\n",
       "6          positive  @VirginAmerica it was amazing, and arrived an ...\n",
       "7          positive  @VirginAmerica I &lt;3 pretty graphics. so muc..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df['airline_sentiment'] == 'positive')\n",
    "temp_df = df[mask]\n",
    "\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Text Cleaning\n",
    "\n",
    "texts = list()\n",
    "\n",
    "for review in temp_df['text']:\n",
    "    \n",
    "    # Remove Emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    review = emoji_pattern.sub(r'', review)\n",
    "    \n",
    "    patterns = ['(http:\\/\\/[a-z0-9]+\\.[a-z]+\\/[a-zA-Z0-9#]+\\/?)',  # Links\n",
    "                '@[A-za-z]+', # Mail\n",
    "                '[^A-Za-z]', # Punctuation\n",
    "               ]\n",
    "    \n",
    "    for patt in patterns:\n",
    "        review = re.sub(pattern=patt, \n",
    "                        repl=' ', \n",
    "                        string=review)\n",
    "    \n",
    "    review = review.lower()\n",
    "    \n",
    "    texts.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Augmentation (By finding Synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Synonyms of the words\n",
    "\n",
    "new_positive_reviews_list1 = list()\n",
    "new_positive_reviews_list2 = list()\n",
    "\n",
    "for text in texts:\n",
    "    text = text.strip().split(' ')\n",
    "    \n",
    "    t_ls1 = list()\n",
    "    t_ls2 = list()\n",
    "    \n",
    "    for character in text:\n",
    "        if character != '':\n",
    "            try:\n",
    "                syns = wordnet.synsets(character)\n",
    "                synonym1 = syns[0].lemmas()[0].name()\n",
    "                synonym2 = syns[0].lemmas()[1].name()\n",
    "                t_ls1.append(synonym1)\n",
    "                t_ls2.append(synonym2)\n",
    "            except Exception as e:\n",
    "                t_ls1.append(character)\n",
    "                t_ls2.append(character)\n",
    "\n",
    "    review1 = ' '.join(t_ls1)\n",
    "    review2 = ' '.join(t_ls2)\n",
    "    \n",
    "    new_positive_reviews_list1.append(review1)\n",
    "    new_positive_reviews_list2.append(review2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  plus you ve added commercials to the experience    tacky \n",
      "asset you ve added commercial to the experience tacky\n",
      "plus you ve added commercial_message to the experience tacky\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])\n",
    "print(new_positive_reviews_list1[0])\n",
    "print(new_positive_reviews_list2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2363\n",
      "2363\n"
     ]
    }
   ],
   "source": [
    "print(len(new_positive_reviews_list1))\n",
    "print(len(new_positive_reviews_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>asset you ve added commercial to the experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>yes about every time iodine fly vx this ear wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>well iodine didn thymine merely now iodine bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>information_technology Washington amaze and ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>iodine lt pretty artwork sol much better than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>positive</td>\n",
       "      <td>love the new aeroplane for the Jack_Kennedy sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>positive</td>\n",
       "      <td>flight Evergreen_State great fantastic cabin c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4723</th>\n",
       "      <td>positive</td>\n",
       "      <td>give_thanks you client dealings will revaluati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4724</th>\n",
       "      <td>positive</td>\n",
       "      <td>thanks He is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4725</th>\n",
       "      <td>positive</td>\n",
       "      <td>give_thanks you we acquire on angstrom_unit di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4726 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     airline_sentiment                                               text\n",
       "0             positive  asset you ve added commercial to the experienc...\n",
       "1             positive  yes about every time iodine fly vx this ear wo...\n",
       "2             positive  well iodine didn thymine merely now iodine bas...\n",
       "3             positive  information_technology Washington amaze and ar...\n",
       "4             positive  iodine lt pretty artwork sol much better than ...\n",
       "...                ...                                                ...\n",
       "4721          positive  love the new aeroplane for the Jack_Kennedy sl...\n",
       "4722          positive  flight Evergreen_State great fantastic cabin c...\n",
       "4723          positive  give_thanks you client dealings will revaluati...\n",
       "4724          positive                                       thanks He is\n",
       "4725          positive  give_thanks you we acquire on angstrom_unit di...\n",
       "\n",
       "[4726 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dict = {\n",
    "    'airline_sentiment': ['positive' for i in range(0, 2363+2363)],\n",
    "    'text': new_positive_reviews_list1 + new_positive_reviews_list2\n",
    "}\n",
    "\n",
    "temp_d = pd.DataFrame(merged_dict) \n",
    "temp_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16262</th>\n",
       "      <td>16262</td>\n",
       "      <td>positive</td>\n",
       "      <td>love the new aeroplane for the Jack_Kennedy sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16263</th>\n",
       "      <td>16263</td>\n",
       "      <td>positive</td>\n",
       "      <td>flight Evergreen_State great fantastic cabin c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16264</th>\n",
       "      <td>16264</td>\n",
       "      <td>positive</td>\n",
       "      <td>give_thanks you client dealings will revaluati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16265</th>\n",
       "      <td>16265</td>\n",
       "      <td>positive</td>\n",
       "      <td>thanks He is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16266</th>\n",
       "      <td>16266</td>\n",
       "      <td>positive</td>\n",
       "      <td>give_thanks you we acquire on angstrom_unit di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16267 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index airline_sentiment  \\\n",
       "0          0          positive   \n",
       "1          1          negative   \n",
       "2          2          negative   \n",
       "3          3          negative   \n",
       "4          4          positive   \n",
       "...      ...               ...   \n",
       "16262  16262          positive   \n",
       "16263  16263          positive   \n",
       "16264  16264          positive   \n",
       "16265  16265          positive   \n",
       "16266  16266          positive   \n",
       "\n",
       "                                                    text  \n",
       "0      @VirginAmerica plus you've added commercials t...  \n",
       "1      @VirginAmerica it's really aggressive to blast...  \n",
       "2      @VirginAmerica and it's a really big bad thing...  \n",
       "3      @VirginAmerica seriously would pay $30 a fligh...  \n",
       "4      @VirginAmerica yes, nearly every time I fly VX...  \n",
       "...                                                  ...  \n",
       "16262  love the new aeroplane for the Jack_Kennedy sl...  \n",
       "16263  flight Evergreen_State great fantastic cabin c...  \n",
       "16264  give_thanks you client dealings will revaluati...  \n",
       "16265                                       thanks He is  \n",
       "16266  give_thanks you we acquire on angstrom_unit di...  \n",
       "\n",
       "[16267 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merged the data\n",
    "\n",
    "df = pd.concat([df, temp_d], ignore_index = True) \n",
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "positive    7089\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.airline_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.56421\n",
       "positive    0.43579\n",
       "Name: airline_sentiment, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved Balanced Augmented Data\n",
    "\n",
    "df.to_csv('Balanced_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list()\n",
    "\n",
    "for review in df['text']:\n",
    "    \n",
    "    # Remove Emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    review = emoji_pattern.sub(r'', review)\n",
    "    \n",
    "    patterns = ['(http:\\/\\/[a-z0-9]+\\.[a-z]+\\/[a-zA-Z0-9#]+\\/?)',  # Links\n",
    "                '@[A-za-z]+', # Mail\n",
    "                '[^A-Za-z]', # Punctuation\n",
    "               ]\n",
    "    \n",
    "    for patt in patterns:\n",
    "        review = re.sub(pattern=patt, \n",
    "                        repl=' ', \n",
    "                        string=review)\n",
    "    \n",
    "    review = review.lower()  # Lower case \n",
    "    review = review.split()  # List of each words\n",
    "        \n",
    "    # StopWords\n",
    "    all_stopwords = set(stopwords.words('english'))  # Set of all Stopwords\n",
    "    all_stopwords.remove('not')\n",
    "    \n",
    "    # Stemming\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    review = [ps.stem(word) for word in review if word not in all_stopwords]\n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'negative':0, 'positive':1}, inplace=True)  # Encode Categorical Dependent Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(list(zip(corpus, df['airline_sentiment'])),\n",
    "                      index = range(0, len(df['airline_sentiment'])),\n",
    "                      columns=['Text', 'Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <-- Save Cleaned Data -->\n",
    "\n",
    "new_df.to_csv('Cleaned_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <-- Convert text into numeric vector -->\n",
    "\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CountVectorizer.pkl','wb') as f:\n",
    "    pickle.dump(cv, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16267x1500 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 128317 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X  # Dependent Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['airline_sentiment']  # Independent Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.80, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Model Details\n",
    "\n",
    "model_names = list()\n",
    "acc = list()\n",
    "tp = list()\n",
    "tn = list()\n",
    "fp = list()\n",
    "fn = list()\n",
    "f1 = list()\n",
    "preci = list()\n",
    "recal = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radnom Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=10, criterion='gini', random_state=0) \n",
    "rf_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   49.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 10.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 92.24 %\n",
      "Best Parameters: {'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 25}\n"
     ]
    }
   ],
   "source": [
    "# <<-- Hyper Parameter Tuning -->>\n",
    "\n",
    "parameters = [{'criterion':['entropy', 'gini'], 'min_samples_split':[2, 4, 8], 'n_estimators':[10, 15, 20, 25, 30]}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = rf_classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 10,\n",
    "                           n_jobs = -1, \n",
    "                           verbose=10)\n",
    "\n",
    "grid_search = grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_   \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new Random Forest model with best parameters\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=25, criterion='entropy', min_samples_split=2, random_state=0) \n",
    "rf_classifier.fit(x_train, y_train)\n",
    "predicted_values = rf_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.77811923786109%\n",
      "\n",
      "Confusion Matrix: \n",
      "[[1769   98]\n",
      " [ 137 1250]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1867\n",
      "           1       0.93      0.90      0.91      1387\n",
      "\n",
      "    accuracy                           0.93      3254\n",
      "   macro avg       0.93      0.92      0.93      3254\n",
      "weighted avg       0.93      0.93      0.93      3254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of model\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted_values)*100\n",
    "cf = confusion_matrix(y_test, predicted_values)\n",
    "report = classification_report(y_test, predicted_values)\n",
    "\n",
    "print(f'Accuracy: {accuracy}%\\n')\n",
    "print(f'Confusion Matrix: \\n{cf}\\n')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "\n",
    "with open('Random_Forest_Model.pkl','wb') as f:\n",
    "    pickle.dump(rf_classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Details\n",
    "\n",
    "algorithm = 'Random Forest'\n",
    "accuracy = round(accuracy_score(y_test, predicted_values), 3)\n",
    "true_positive = cf[0][0]\n",
    "true_negative = cf[1][1]\n",
    "false_positive = cf[0][1]\n",
    "false_negative = cf[1][0]\n",
    "F1_score = round(f1_score(y_test, predicted_values), 3) \n",
    "Precision_score = round(precision_score(y_test, predicted_values), 3)\n",
    "Recall_score = round(recall_score(y_test, predicted_values), 3)\n",
    "\n",
    "model_names.append(algorithm)\n",
    "acc.append(accuracy)\n",
    "tp.append(true_positive)\n",
    "tn.append(true_negative)\n",
    "fp.append(false_positive)\n",
    "fn.append(false_negative)\n",
    "f1.append(F1_score)\n",
    "preci.append(Precision_score)\n",
    "recal.append(Recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_classifier = XGBClassifier()\n",
    "xgboost_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 23.1min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 43.6min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 64.5min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 80.7min\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed: 117.4min remaining: 25.8min\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed: 138.1min remaining:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 141.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 92.86 %\n",
      "Best Parameters: {'n_estimators': 389, 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "# <<-- Hyper Parameter Tuning -->>\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 600, num = 20)]\n",
    "max_depth = [int(x) for x in np.linspace(5, 20, num = 6)]\n",
    "\n",
    "parameters = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = xgboost_classifier,\n",
    "                           param_distributions  = parameters,\n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 5,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=10)\n",
    "\n",
    "random_search = random_search.fit(x_train, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_   \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new XGBoost model with best parameters\n",
    "\n",
    "xgboost_classifier = XGBClassifier(n_estimators=389, max_depth=8)\n",
    "xgboost_classifier.fit(x_train, y_train)\n",
    "predicted_values = xgboost_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.76152427781193%\n",
      "\n",
      "Confusion Matrix: \n",
      "[[1780   87]\n",
      " [ 116 1271]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      1867\n",
      "           1       0.94      0.92      0.93      1387\n",
      "\n",
      "    accuracy                           0.94      3254\n",
      "   macro avg       0.94      0.93      0.94      3254\n",
      "weighted avg       0.94      0.94      0.94      3254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of model\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted_values)*100\n",
    "cf = confusion_matrix(y_test, predicted_values)\n",
    "report = classification_report(y_test, predicted_values)\n",
    "\n",
    "print(f'Accuracy: {accuracy}%\\n')\n",
    "print(f'Confusion Matrix: \\n{cf}\\n')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "\n",
    "with open('XGBoost_Model.pkl','wb') as f:\n",
    "    pickle.dump(xgboost_classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Details\n",
    "\n",
    "algorithm = 'XGBoost'\n",
    "accuracy = round(accuracy_score(y_test, predicted_values), 3)\n",
    "true_positive = cf[0][0]\n",
    "true_negative = cf[1][1]\n",
    "false_positive = cf[0][1]\n",
    "false_negative = cf[1][0]\n",
    "F1_score = round(f1_score(y_test, predicted_values), 3) \n",
    "Precision_score = round(precision_score(y_test, predicted_values), 3)\n",
    "Recall_score = round(recall_score(y_test, predicted_values), 3)\n",
    "\n",
    "model_names.append(algorithm)\n",
    "acc.append(accuracy)\n",
    "tp.append(true_positive)\n",
    "tn.append(true_negative)\n",
    "fp.append(false_positive)\n",
    "fn.append(false_negative)\n",
    "f1.append(F1_score)\n",
    "preci.append(Precision_score)\n",
    "recal.append(Recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightgbm_classifier = LGBMClassifier()\n",
    "lightgbm_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   39.6s remaining:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   41.4s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   42.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 92.73 %\n",
      "Best Parameters: {'n_estimators': 475, 'max_depth': 14}\n"
     ]
    }
   ],
   "source": [
    "# <<-- Hyper Parameter Tuning -->>\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 300, stop = 600, num = 25)]\n",
    "max_depth = [int(x) for x in np.linspace(5, 20, num = 6)]\n",
    "\n",
    "parameters = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = lightgbm_classifier,\n",
    "                           param_distributions  = parameters,\n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 5,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=10)\n",
    "\n",
    "random_search = random_search.fit(x_train, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_   \n",
    "best_parameters = random_search.best_params_   \n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "# Make new LGBM model with best parameters\n",
    "\n",
    "lightgbm_classifier = LGBMClassifier(n_estimators=475, max_depth=14)\n",
    "lightgbm_classifier.fit(x_train, y_train)\n",
    "predicted_values = lightgbm_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.4542102028273%\n",
      "\n",
      "Confusion Matrix: \n",
      "[[1774   93]\n",
      " [ 120 1267]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      1867\n",
      "           1       0.93      0.91      0.92      1387\n",
      "\n",
      "    accuracy                           0.93      3254\n",
      "   macro avg       0.93      0.93      0.93      3254\n",
      "weighted avg       0.93      0.93      0.93      3254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of model\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted_values)*100\n",
    "cf = confusion_matrix(y_test, predicted_values)\n",
    "report = classification_report(y_test, predicted_values)\n",
    "\n",
    "print(f'Accuracy: {accuracy}%\\n')\n",
    "print(f'Confusion Matrix: \\n{cf}\\n')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "\n",
    "with open('LGBM_Model.pkl','wb') as f:\n",
    "    pickle.dump(lightgbm_classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Details\n",
    "\n",
    "algorithm = 'LGBM'\n",
    "accuracy = round(accuracy_score(y_test, predicted_values), 3)\n",
    "true_positive = cf[0][0]\n",
    "true_negative = cf[1][1]\n",
    "false_positive = cf[0][1]\n",
    "false_negative = cf[1][0]\n",
    "F1_score = round(f1_score(y_test, predicted_values), 3) \n",
    "Precision_score = round(precision_score(y_test, predicted_values), 3)\n",
    "Recall_score = round(recall_score(y_test, predicted_values), 3)\n",
    "\n",
    "model_names.append(algorithm)\n",
    "acc.append(accuracy)\n",
    "tp.append(true_positive)\n",
    "tn.append(true_negative)\n",
    "fp.append(false_positive)\n",
    "fn.append(false_negative)\n",
    "f1.append(F1_score)\n",
    "preci.append(Precision_score)\n",
    "recal.append(Recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 06m 40s]\n",
      "val_accuracy: 0.9342347979545593\n",
      "\n",
      "Best val_accuracy So Far: 0.9440688490867615\n",
      "Total elapsed time: 01h 07m 29s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "class MyHyperModel(HyperModel):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        for i in range(hp.Int('num_layers', 2, 20)):\n",
    "            model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                                min_value=32,\n",
    "                                                max_value=512,\n",
    "                                                step=32),\n",
    "                                   activation='relu'))\n",
    "        model.add(layers.Dense(self.num_classes, activation='sigmoid'))\n",
    "        model.compile(\n",
    "                    optimizer=keras.optimizers.Adam(\n",
    "                          hp.Choice('learning_rate',\n",
    "                          values=[1e-2, 1e-3, 1e-4])),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "\n",
    "hypermodel = MyHyperModel(num_classes=1)\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    directory='my_dir',\n",
    "    project_name='helloworld')\n",
    "\n",
    "tuner.search(x_train, y_train,\n",
    "             epochs=100,\n",
    "             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-8._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-7.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-7.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-7.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-7.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-8._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-9._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-9.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-9.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-10._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-11._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-11.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-11.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-12._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-12.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-12.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-13._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-13.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-13.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-14._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-14.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-14.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-15._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-15.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-15.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-16._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-16.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-16.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-7.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-7.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-9.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-9.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-11.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-11.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-12.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-12.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-13.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-13.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-14.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-14.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-15.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-15.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-16.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-16.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-7.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-7.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-8.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-8.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-9.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-9.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-11.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-11.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-12.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-12.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-13.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-13.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-14.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-14.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-15.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-15.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-16.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-16.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models(num_models=2)[0] # Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir\\helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 16\n",
      "units_0: 384\n",
      "units_1: 256\n",
      "learning_rate: 0.001\n",
      "units_2: 64\n",
      "units_3: 32\n",
      "units_4: 224\n",
      "units_5: 256\n",
      "units_6: 96\n",
      "units_7: 224\n",
      "units_8: 32\n",
      "units_9: 448\n",
      "units_10: 352\n",
      "units_11: 288\n",
      "units_12: 384\n",
      "units_13: 448\n",
      "units_14: 416\n",
      "units_15: 32\n",
      "Score: 0.9440688490867615\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 8\n",
      "units_0: 160\n",
      "units_1: 160\n",
      "learning_rate: 0.001\n",
      "units_2: 384\n",
      "units_3: 192\n",
      "units_4: 160\n",
      "units_5: 160\n",
      "units_6: 64\n",
      "units_7: 192\n",
      "units_8: 480\n",
      "units_9: 384\n",
      "units_10: 320\n",
      "units_11: 352\n",
      "units_12: 352\n",
      "units_13: 192\n",
      "units_14: 416\n",
      "units_15: 416\n",
      "Score: 0.9431468844413757\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 192\n",
      "units_1: 416\n",
      "learning_rate: 0.0001\n",
      "units_2: 352\n",
      "units_3: 288\n",
      "units_4: 288\n",
      "units_5: 288\n",
      "units_6: 352\n",
      "units_7: 96\n",
      "units_8: 64\n",
      "units_9: 352\n",
      "units_10: 128\n",
      "units_11: 352\n",
      "units_12: 352\n",
      "units_13: 384\n",
      "units_14: 128\n",
      "units_15: 320\n",
      "Score: 0.9428395628929138\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 6\n",
      "units_0: 384\n",
      "units_1: 448\n",
      "learning_rate: 0.01\n",
      "units_2: 96\n",
      "units_3: 192\n",
      "units_4: 160\n",
      "units_5: 448\n",
      "units_6: 192\n",
      "units_7: 64\n",
      "units_8: 160\n",
      "units_9: 512\n",
      "units_10: 192\n",
      "units_11: 480\n",
      "units_12: 288\n",
      "units_13: 288\n",
      "units_14: 448\n",
      "Score: 0.941303014755249\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 8\n",
      "units_0: 128\n",
      "units_1: 480\n",
      "learning_rate: 0.01\n",
      "units_2: 320\n",
      "units_3: 512\n",
      "units_4: 160\n",
      "units_5: 384\n",
      "units_6: 128\n",
      "units_7: 480\n",
      "units_8: 448\n",
      "units_9: 512\n",
      "units_10: 224\n",
      "units_11: 448\n",
      "units_12: 192\n",
      "units_13: 160\n",
      "units_14: 448\n",
      "Score: 0.9406883716583252\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 13\n",
      "units_0: 160\n",
      "units_1: 448\n",
      "learning_rate: 0.0001\n",
      "units_2: 320\n",
      "units_3: 96\n",
      "units_4: 64\n",
      "units_5: 64\n",
      "units_6: 192\n",
      "units_7: 416\n",
      "units_8: 352\n",
      "units_9: 64\n",
      "units_10: 288\n",
      "units_11: 128\n",
      "units_12: 64\n",
      "units_13: 256\n",
      "units_14: 128\n",
      "units_15: 352\n",
      "Score: 0.9406883716583252\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 9\n",
      "units_0: 192\n",
      "units_1: 96\n",
      "learning_rate: 0.0001\n",
      "units_2: 256\n",
      "units_3: 128\n",
      "units_4: 512\n",
      "units_5: 192\n",
      "units_6: 352\n",
      "units_7: 96\n",
      "units_8: 352\n",
      "units_9: 448\n",
      "units_10: 320\n",
      "units_11: 352\n",
      "units_12: 96\n",
      "units_13: 128\n",
      "units_14: 320\n",
      "Score: 0.9391518235206604\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 8\n",
      "units_0: 128\n",
      "units_1: 160\n",
      "learning_rate: 0.01\n",
      "units_2: 416\n",
      "units_3: 352\n",
      "units_4: 224\n",
      "units_5: 512\n",
      "units_6: 512\n",
      "units_7: 256\n",
      "units_8: 160\n",
      "units_9: 384\n",
      "units_10: 256\n",
      "units_11: 224\n",
      "units_12: 480\n",
      "units_13: 64\n",
      "units_14: 256\n",
      "units_15: 32\n",
      "Score: 0.9379225373268127\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 13\n",
      "units_0: 64\n",
      "units_1: 416\n",
      "learning_rate: 0.01\n",
      "units_2: 96\n",
      "units_3: 384\n",
      "units_4: 64\n",
      "units_5: 192\n",
      "units_6: 224\n",
      "units_7: 480\n",
      "units_8: 128\n",
      "units_9: 416\n",
      "units_10: 64\n",
      "units_11: 96\n",
      "units_12: 288\n",
      "units_13: 512\n",
      "units_14: 384\n",
      "units_15: 96\n",
      "Score: 0.9342347979545593\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 15\n",
      "units_0: 448\n",
      "units_1: 192\n",
      "learning_rate: 0.01\n",
      "units_2: 32\n",
      "units_3: 32\n",
      "units_4: 32\n",
      "units_5: 32\n",
      "units_6: 32\n",
      "units_7: 32\n",
      "units_8: 32\n",
      "units_9: 32\n",
      "units_10: 32\n",
      "units_11: 32\n",
      "units_12: 32\n",
      "units_13: 32\n",
      "units_14: 32\n",
      "Score: 0.9299324154853821\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()  # Summary of the tuner that experimented deifferent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1a6b802ba88>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 6ms/step - loss: 0.4478 - accuracy: 0.9441\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on testing data\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 384)               576384    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               98560     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 224)               7392      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               57600     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 96)                24672     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 224)               21728     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                7200      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 448)               14784     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 352)               158048    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 288)               101664    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 384)               110976    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 448)               172480    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 416)               186784    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                13344     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,570,177\n",
      "Trainable params: 1,570,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # Best model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preidict values\n",
    "\n",
    "predicted_values = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.5  # Threshold\n",
    "\n",
    "predicted_values = [1 if i[0] > thresh else 0 for i in predicted_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.40688383527966%\n",
      "\n",
      "Confusion Matrix: \n",
      "[[1777   90]\n",
      " [  92 1295]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      1867\n",
      "           1       0.94      0.93      0.93      1387\n",
      "\n",
      "    accuracy                           0.94      3254\n",
      "   macro avg       0.94      0.94      0.94      3254\n",
      "weighted avg       0.94      0.94      0.94      3254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of model\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted_values)*100\n",
    "cf = confusion_matrix(y_test, predicted_values)\n",
    "report = classification_report(y_test, predicted_values)\n",
    "\n",
    "print(f'Accuracy: {accuracy}%\\n')\n",
    "print(f'Confusion Matrix: \\n{cf}\\n')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Details\n",
    "\n",
    "algorithm = 'ANN'\n",
    "accuracy = round(accuracy_score(y_test, predicted_values), 3)\n",
    "true_positive = cf[0][0]\n",
    "true_negative = cf[1][1]\n",
    "false_positive = cf[0][1]\n",
    "false_negative = cf[1][0]\n",
    "F1_score = round(f1_score(y_test, predicted_values), 3) \n",
    "Precision_score = round(precision_score(y_test, predicted_values), 3)\n",
    "Recall_score = round(recall_score(y_test, predicted_values), 3)\n",
    "\n",
    "model_names.append(algorithm)\n",
    "acc.append(accuracy)\n",
    "tp.append(true_positive)\n",
    "tn.append(true_negative)\n",
    "fp.append(false_positive)\n",
    "fn.append(false_negative)\n",
    "f1.append(F1_score)\n",
    "preci.append(Precision_score)\n",
    "recal.append(Recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<-- Save Model in HDF5 file format -->>\n",
    "\n",
    "model.save(\"ANN_Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 6ms/step - loss: 0.4478 - accuracy: 0.9441\n"
     ]
    }
   ],
   "source": [
    "# <<-- Load the saved model -->>\n",
    "\n",
    "loaded_model = load_model(\"ANN_Model.h5\") # Load the model\n",
    "loss, accuracy = loaded_model.evaluate(x_test, y_test) # Test the accuracy on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all Model Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.928</td>\n",
       "      <td>1769</td>\n",
       "      <td>1250</td>\n",
       "      <td>98</td>\n",
       "      <td>137</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.938</td>\n",
       "      <td>1780</td>\n",
       "      <td>1271</td>\n",
       "      <td>87</td>\n",
       "      <td>116</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.935</td>\n",
       "      <td>1774</td>\n",
       "      <td>1267</td>\n",
       "      <td>93</td>\n",
       "      <td>120</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.944</td>\n",
       "      <td>1777</td>\n",
       "      <td>1295</td>\n",
       "      <td>90</td>\n",
       "      <td>92</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Accuracy    TP    TN  FP   FN     f1  precision  recall\n",
       "1  Random Forest     0.928  1769  1250  98  137  0.914      0.927   0.901\n",
       "2        XGBoost     0.938  1780  1271  87  116  0.926      0.936   0.916\n",
       "3           LGBM     0.935  1774  1267  93  120  0.922      0.932   0.913\n",
       "4            ANN     0.944  1777  1295  90   92  0.934      0.935   0.934"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_summary_df = pd.DataFrame(list(zip(model_names, acc, tp, tn, fp, fn, f1, preci, recal)),\n",
    "            index = range(1, 5, 1), \n",
    "            columns=['Model', 'Accuracy', 'TP', 'TN', 'FP', 'FN', 'f1', 'precision', 'recall'])\n",
    "all_models_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_summary_df.to_csv('Summary.csv')  # Save data to csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Prediction (Using OOPS Concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysis:\n",
    "    def __init__(self, text):\n",
    "        self.review = text\n",
    "        self.copy_review = self.review\n",
    "\n",
    "        self.emoji_pattern = re.compile(\"[\"\n",
    "                                        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                        \"]+\", flags=re.UNICODE)\n",
    "\n",
    "        self.patterns = ['(http:\\/\\/[a-z0-9]+\\.[a-z]+\\/[a-zA-Z0-9#]+\\/?)',  # Links\n",
    "                         '@[A-za-z]+',  # Mail\n",
    "                         '[^A-Za-z]',  # Punctuation\n",
    "                         ]\n",
    "\n",
    "    def clean_text(self):\n",
    "        for patt in self.patterns:\n",
    "            self.review = re.sub(pattern=patt,\n",
    "                                 repl=' ',\n",
    "                                 string=self.review)\n",
    "\n",
    "        self.review = self.review.lower()  # Lower case\n",
    "        self.review = self.review.split()  # List of each words\n",
    "\n",
    "        # StopWords\n",
    "        all_stopwords = set(stopwords.words('english'))  # Set of all Stopwords\n",
    "        all_stopwords.remove('not')\n",
    "\n",
    "        # Stemming\n",
    "        ps = PorterStemmer()\n",
    "\n",
    "        self.review = [ps.stem(word) for word in self.review if word not in all_stopwords]\n",
    "        self.review = ' '.join(self.review)\n",
    "\n",
    "    def bag_of_words(self):\n",
    "        new_corpus = [self.review]\n",
    "\n",
    "        with open('CountVectorizer.pkl', 'rb') as f:\n",
    "            new_cv = pickle.load(f)\n",
    "\n",
    "        self.review = new_cv.transform(new_corpus).toarray()\n",
    "\n",
    "    def predict(self):\n",
    "        loaded_model = load_model(\"ANN_Model.h5\")  # Load the model\n",
    "        prediction = loaded_model.predict(self.review)\n",
    "\n",
    "        thresh = 0.5  # Threshold\n",
    "        prediction = [1 if i[0] > thresh else 0 for i in prediction]\n",
    "\n",
    "        text = self.copy_review\n",
    "\n",
    "        if prediction[0] == 1:\n",
    "            sentiment = 'Positive'\n",
    "        else:\n",
    "            sentiment = 'Negative'\n",
    "\n",
    "        # Model Summary\n",
    "        stringlist = []\n",
    "        loaded_model.summary(print_fn=lambda x: stringlist.append(x))\n",
    "        model_summary = \" \".join(stringlist)\n",
    "\n",
    "        data = {'Text': text,\n",
    "                'Sentiment': sentiment,\n",
    "                'Model': 'ANN',\n",
    "                'Model_Summary': model_summary\n",
    "                }\n",
    "\n",
    "        json_object = json.dumps(data, indent=4)\n",
    "\n",
    "        return sentiment, json_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Positive',\n",
       " '{\\n    \"Text\": \"It was a good experience\",\\n    \"Sentiment\": \"Positive\",\\n    \"Model\": \"ANN\",\\n    \"Model_Summary\": \"Model: \\\\\"sequential\\\\\" _________________________________________________________________ Layer (type)                 Output Shape              Param #    ================================================================= dense (Dense)                (None, 384)               576384     _________________________________________________________________ dense_1 (Dense)              (None, 256)               98560      _________________________________________________________________ dense_2 (Dense)              (None, 64)                16448      _________________________________________________________________ dense_3 (Dense)              (None, 32)                2080       _________________________________________________________________ dense_4 (Dense)              (None, 224)               7392       _________________________________________________________________ dense_5 (Dense)              (None, 256)               57600      _________________________________________________________________ dense_6 (Dense)              (None, 96)                24672      _________________________________________________________________ dense_7 (Dense)              (None, 224)               21728      _________________________________________________________________ dense_8 (Dense)              (None, 32)                7200       _________________________________________________________________ dense_9 (Dense)              (None, 448)               14784      _________________________________________________________________ dense_10 (Dense)             (None, 352)               158048     _________________________________________________________________ dense_11 (Dense)             (None, 288)               101664     _________________________________________________________________ dense_12 (Dense)             (None, 384)               110976     _________________________________________________________________ dense_13 (Dense)             (None, 448)               172480     _________________________________________________________________ dense_14 (Dense)             (None, 416)               186784     _________________________________________________________________ dense_15 (Dense)             (None, 32)                13344      _________________________________________________________________ dense_16 (Dense)             (None, 1)                 33         ================================================================= Total params: 1,570,177 Trainable params: 1,570,177 Non-trainable params: 0 _________________________________________________________________\"\\n}')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = SentimentAnalysis('It was a good experience')\n",
    "obj.clean_text()\n",
    "obj.bag_of_words()\n",
    "obj.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 208 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A6BCDCC3A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Negative',\n",
       " '{\\n    \"Text\": \"It was a awful experience\",\\n    \"Sentiment\": \"Negative\",\\n    \"Model\": \"ANN\",\\n    \"Model_Summary\": \"Model: \\\\\"sequential\\\\\" _________________________________________________________________ Layer (type)                 Output Shape              Param #    ================================================================= dense (Dense)                (None, 384)               576384     _________________________________________________________________ dense_1 (Dense)              (None, 256)               98560      _________________________________________________________________ dense_2 (Dense)              (None, 64)                16448      _________________________________________________________________ dense_3 (Dense)              (None, 32)                2080       _________________________________________________________________ dense_4 (Dense)              (None, 224)               7392       _________________________________________________________________ dense_5 (Dense)              (None, 256)               57600      _________________________________________________________________ dense_6 (Dense)              (None, 96)                24672      _________________________________________________________________ dense_7 (Dense)              (None, 224)               21728      _________________________________________________________________ dense_8 (Dense)              (None, 32)                7200       _________________________________________________________________ dense_9 (Dense)              (None, 448)               14784      _________________________________________________________________ dense_10 (Dense)             (None, 352)               158048     _________________________________________________________________ dense_11 (Dense)             (None, 288)               101664     _________________________________________________________________ dense_12 (Dense)             (None, 384)               110976     _________________________________________________________________ dense_13 (Dense)             (None, 448)               172480     _________________________________________________________________ dense_14 (Dense)             (None, 416)               186784     _________________________________________________________________ dense_15 (Dense)             (None, 32)                13344      _________________________________________________________________ dense_16 (Dense)             (None, 1)                 33         ================================================================= Total params: 1,570,177 Trainable params: 1,570,177 Non-trainable params: 0 _________________________________________________________________\"\\n}')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = SentimentAnalysis('It was a awful experience')\n",
    "obj.clean_text()\n",
    "obj.bag_of_words()\n",
    "obj.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
